// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: ai/v1/ai.proto

package aiv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// LLMRequest is a request message for invoking LLM services.
// Contains optional id and text parameters for processing.
type LLMRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Text          string                 `protobuf:"bytes,2,opt,name=text,proto3" json:"text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

// Reset resets the LLMRequest to its zero value state.
// This clears all fields and resets internal protobuf state.
func (x *LLMRequest) Reset() {
	*x = LLMRequest{}
	mi := &file_ai_v1_ai_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

// String returns the string representation of the LLMRequest message.
// Implements the Stringer interface for LLMRequest.
func (x *LLMRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

// ProtoMessage marks LLMRequest as implementing the protobuf Message interface.
func (*LLMRequest) ProtoMessage() {}

// ProtoReflect returns the protobuf reflection information for this message.
// Provides access to the message descriptor and implementation details.
func (x *LLMRequest) ProtoReflect() protoreflect.Message {
	mi := &file_ai_v1_ai_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Descriptor returns the raw protobuf descriptor for this message type.
// Deprecated: Use ProtoReflect.Descriptor instead.
func (*LLMRequest) Descriptor() ([]byte, []int) {
	return file_ai_v1_ai_proto_rawDescGZIP(), []int{0}
}

// GetId returns the Id field value, or an empty string if the field is not set.
func (x *LLMRequest) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

// GetText returns the Text field value, or an empty string if the field is not set.
func (x *LLMRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

// StreamEvent represents a streaming event in the LLM service communication.
// Contains status flags and content data for streaming responses.
type StreamEvent struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	Final            bool                   `protobuf:"varint,1,opt,name=final,proto3" json:"final,omitempty"`
	ReasoningContent string                 `protobuf:"bytes,2,opt,name=reasoningContent,proto3" json:"reasoningContent,omitempty"`
	Content          string                 `protobuf:"bytes,3,opt,name=content,proto3" json:"content,omitempty"`
	Err              string                 `protobuf:"bytes,4,opt,name=err,proto3" json:"err,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

// Reset resets the StreamEvent to its zero value state.
// This clears all fields and resets internal protobuf state.
func (x *StreamEvent) Reset() {
	*x = StreamEvent{}
	mi := &file_ai_v1_ai_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

// String returns the string representation of the StreamEvent message.
// Implements the Stringer interface for StreamEvent.
func (x *StreamEvent) String() string {
	return protoimpl.X.MessageStringOf(x)
}

// ProtoMessage marks StreamEvent as implementing the protobuf Message interface.
func (*StreamEvent) ProtoMessage() {}

// ProtoReflect returns the protobuf reflection information for this message.
// Provides access to the message descriptor and implementation details.
func (x *StreamEvent) ProtoReflect() protoreflect.Message {
	mi := &file_ai_v1_ai_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Descriptor returns the raw protobuf descriptor for this message type.
// Deprecated: Use ProtoReflect.Descriptor instead.
func (*StreamEvent) Descriptor() ([]byte, []int) {
	return file_ai_v1_ai_proto_rawDescGZIP(), []int{1}
}

// GetFinal returns whether this stream event is the final message in the stream.
func (x *StreamEvent) GetFinal() bool {
	if x != nil {
		return x.Final
	}
	return false
}

// GetReasoningContent returns the reasoning content from the stream event,
// or an empty string if the field is not set.
func (x *StreamEvent) GetReasoningContent() string {
	if x != nil {
		return x.ReasoningContent
	}
	return ""
}

// GetContent returns the content from the stream event,
// or an empty string if the field is not set.
func (x *StreamEvent) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

// GetErr returns any error message associated with the stream event,
// or an empty string if no error occurred.
func (x *StreamEvent) GetErr() string {
	if x != nil {
		return x.Err
	}
	return ""
}

// LLMResponse represents a complete response from the LLM service.
// Contains processed content and reasoning information.
type LLMResponse struct {
	state            protoimpl.MessageState `protogen:"open.v1"`
	ReasoningContent string                 `protobuf:"bytes,1,opt,name=reasoningContent,proto3" json:"reasoningContent,omitempty"`
	Content          string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

// Reset resets the LLMResponse to its zero value state.
// This clears all fields and resets internal protobuf state.
func (x *LLMResponse) Reset() {
	*x = LLMResponse{}
	mi := &file_ai_v1_ai_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

// String returns the string representation of the LLMResponse message.
// Implements the Stringer interface for LLMResponse.
func (x *LLMResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

// ProtoMessage marks LLMResponse as implementing the protobuf Message interface.
func (*LLMResponse) ProtoMessage() {}

// ProtoReflect returns the protobuf reflection information for this message.
// Provides access to the message descriptor and implementation details.
func (x *LLMResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_v1_ai_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Descriptor returns the raw protobuf descriptor for this message type.
// Deprecated: Use ProtoReflect.Descriptor instead.
func (*LLMResponse) Descriptor() ([]byte, []int) {
	return file_ai_v1_ai_proto_rawDescGZIP(), []int{2}
}

// GetReasoningContent returns the reasoning content from the response,
// or an empty string if the field is not set.
func (x *LLMResponse) GetReasoningContent() string {
	if x != nil {
		return x.ReasoningContent
	}
	return ""
}

// GetContent returns the content from the response,
// or an empty string if the field is not set.
func (x *LLMResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

var File_ai_v1_ai_proto protoreflect.FileDescriptor

const file_ai_v1_ai_proto_rawDesc = "" +
	"\n" +
	"\x0eai/v1/ai.proto\x12\x05ai.v1\"0\n" +
	"\n" +
	"LLMRequest\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04text\x18\x02 \x01(\tR\x04text\"{\n" +
	"\vStreamEvent\x12\x14\n" +
	"\x05final\x18\x01 \x01(\bR\x05final\x12*\n" +
	"\x10reasoningContent\x18\x02 \x01(\tR\x10reasoningContent\x12\x18\n" +
	"\acontent\x18\x03 \x01(\tR\acontent\x12\x10\n" +
	"\x03err\x18\x04 \x01(\tR\x03err\"S\n" +
	"\vLLMResponse\x12*\n" +
	"\x10reasoningContent\x18\x01 \x01(\tR\x10reasoningContent\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent2o\n" +
	"\tAIService\x12/\n" +
	"\x06Invoke\x12\x11.ai.v1.LLMRequest\x1a\x12.ai.v1.LLMResponse\x121\n" +
	"\x06Stream\x12\x11.ai.v1.LLMRequest\x1a\x12.ai.v1.StreamEvent0\x01B\x80\x01\n" +
	"\tcom.ai.v1B\aAiProtoP\x01Z5github.com/ecodeclub/ai-gateway-go/api/gen/ai/v1;aiv1\xa2\x02\x03AXX\xaa\x02\x05Ai.V1\xca\x02\x05Ai\\V1\xe2\x02\x11Ai\\V1\\GPBMetadata\xea\x02\x06Ai::V1b\x06proto3"

var (
	file_ai_v1_ai_proto_rawDescOnce sync.Once
	file_ai_v1_ai_proto_rawDescData []byte
)

// file_ai_v1_ai_proto_rawDescGZIP returns the GZIP-compressed raw descriptor
// for the ai/v1/ai.proto file. This contains the complete protobuf schema.
func file_ai_v1_ai_proto_rawDescGZIP() []byte {
	file_ai_v1_ai_proto_rawDescOnce.Do(func() {
		file_ai_v1_ai_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_ai_v1_ai_proto_rawDesc), len(file_ai_v1_ai_proto_rawDesc)))
	})
	return file_ai_v1_ai_proto_rawDescData
}

var file_ai_v1_ai_proto_msgTypes = make([]protoimpl.MessageInfo, 3)
var file_ai_v1_ai_proto_goTypes = []any{
	(*LLMRequest)(nil),  // 0: ai.v1.LLMRequest
	(*StreamEvent)(nil), // 1: ai.v1.StreamEvent
	(*LLMResponse)(nil), // 2: ai.v1.LLMResponse
}
var file_ai_v1_ai_proto_depIdxs = []int32{
	0, // 0: ai.v1.AIService.Invoke:input_type -> ai.v1.LLMRequest
	0, // 1: ai.v1.AIService.Stream:input_type -> ai.v1.LLMRequest
	2, // 2: ai.v1.AIService.Invoke:output_type -> ai.v1.LLMResponse
	1, // 3: ai.v1.AIService.Stream:output_type -> ai.v1.StreamEvent
	2, // [2:4] is the sub-list for method output_type
	0, // [0:2] is the sub-list for method input_type
	0, // [0:0] is the sub-list for extension type_name
	0, // [0:0] is the sub-list for extension extendee
	0, // [0:0] is the sub-list for field type_name
}

// init initializes the file descriptor for ai/v1/ai.proto.
// This sets up the protobuf metadata for all messages defined in this file.
func init() { file_ai_v1_ai_proto_init() }

// file_ai_v1_ai_proto_init performs the actual initialization of the file descriptor.
// It creates the type information for all messages and services defined in ai/v1/ai.proto.
func file_ai_v1_ai_proto_init() {
	if File_ai_v1_ai_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_ai_v1_ai_proto_rawDesc), len(file_ai_v1_ai_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   3,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_ai_v1_ai_proto_goTypes,
		DependencyIndexes: file_ai_v1_ai_proto_depIdxs,
		MessageInfos:      file_ai_v1_ai_proto_msgTypes,
	}.Build()
	File_ai_v1_ai_proto = out.File
	file_ai_v1_ai_proto_goTypes = nil
	file_ai_v1_ai_proto_depIdxs = nil
}
